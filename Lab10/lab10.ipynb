{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hashlib as hl\n",
    "import random as rd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_win(state):\n",
    "    state=np.array(state).reshape(3,3)\n",
    "     # Controllare le righe e le colonne\n",
    "    for i in range(3):\n",
    "        # Controllare le righe\n",
    "        if all(state[i, j] == state[i, 0] and state[i, 0] != ' ' for j in range(3)):\n",
    "            return True\n",
    "        # Controllare le colonne\n",
    "        if all(state[j, i] == state[0, i] and state[0, i] != ' ' for j in range(3)):\n",
    "            return True\n",
    "    # Controllare le diagonali\n",
    "    if state[0, 0] == state[1, 1] == state[2, 2] and state[0, 0] != ' ':\n",
    "        return True\n",
    "    if state[0, 2] == state[1, 1] == state[2, 0] and state[0, 2] != ' ':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer:\n",
    "    def __init__(self, symbol):\n",
    "        self.symbol = symbol\n",
    "\n",
    "    def make_move(self, state):\n",
    "        empty_cells = np.where(np.array(state) == ' ')[0]\n",
    "        action = np.random.choice(len(empty_cells))   \n",
    "        state[action] = self.symbol\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QLearningAgent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def check_pattern(state,symbol):\n",
    "    if symbol=='X':\n",
    "        opp='O'\n",
    "    else:\n",
    "        opp='X'\n",
    "    for i in [1,2,3,4,5,6,7,8]:\n",
    "        for p in [0,2,6,8]:\n",
    "            if i!=p and state[i]==opp and state[p]==symbol:\n",
    "                return 3 #wherever the opp starts to play take a corner \n",
    "    if (state==[' ',' ',' ',' ',symbol,' ',' ',' ',' ']\n",
    "        or state==[' ',symbol,' ',' ',' ',' ',' ',' ',' ']\n",
    "        or state==[' ',' ',' ',symbol,' ',' ',' ',' ',' ']\n",
    "        or state==[' ',' ',' ',' ',' ',symbol,' ',' ',' ']\n",
    "        or state==[' ',' ',' ',' ',' ',' ',' ',symbol,' ']):\n",
    "        return -5 #penalize starting from the sides (1,3,5,7) and from the center\n",
    "    if (state==[symbol,' ',' ',' ',' ',' ',' ',' ',' '] \n",
    "       or state==[' ',' ',symbol,' ',' ',' ',' ',' ',' '] \n",
    "       or state==[' ',' ',' ',' ',' ',' ',symbol,' ',' ']\n",
    "       or state==[' ',' ',' ',' ',' ',' ',' ',' ',symbol]) :\n",
    "        return 3 #encourage starting from the corner\n",
    "    for o in [1,3,5,7]:\n",
    "        for p in [0,2,6,8]:\n",
    "            if (state[o]==opp and state[p]==symbol and (state[2]==symbol \n",
    "            or state[6]==symbol or state[8]==symbol) and state.count(' ')==6):\n",
    "                return 3 #if opp took a side and you already own a corner take one of the other corners\n",
    "    if (state==[symbol,' ',' ',' ',opp,' ',' ',' ',symbol] \n",
    "       or state==[' ',' ',symbol,' ',opp,' ',symbol,' ',' '] \n",
    "       or state==[symbol,' ',' ',' ',opp,' ',symbol,' ',' ']\n",
    "       or state==[' ',' ',symbol,' ',opp,' ',' ',' ',symbol]\n",
    "       or state==[symbol,' ',symbol,' ',opp,' ',' ',' ',' ']\n",
    "       or state==[' ',' ',' ',' ',opp,' ',symbol,' ',symbol]) :\n",
    "        return 3 # if opp took the center take the opposite corner or the same corner in the row/col\n",
    "    \n",
    "    for i in range(3):\n",
    "        c=Counter(state[i:9:3])\n",
    "        if c[\"symbol\"]==1 and c[\"opp\"]==2:\n",
    "            return 4 #block opp on col\n",
    "        c=Counter(state[i:i+3])\n",
    "        if c[\"symbol\"]==1 and c[\"opp\"]==2:\n",
    "            return 4 #block opp on rows\n",
    "    c=Counter(state[0:9:4])\n",
    "    if c[\"symbol\"]==1 and c[\"opp\"]==2:\n",
    "        return 4 #block opp on main diag\n",
    "    c=Counter(state[2:7:2])\n",
    "    if c[\"symbol\"]==1 and c[\"opp\"]==2:\n",
    "        return 4 #block opp on secondary diag\n",
    "\n",
    "    if (state.count(' ')==5 and ((state[0]==state[2]==state[6]==symbol) or (state[0]==state[2]==state[8]==symbol) \n",
    "    or (state[0]==state[6]==state[8]==symbol) or (state[2]==state[6]==state[8]==symbol))):\n",
    "        return 3 #make triangles (take three corners)\n",
    "    \n",
    "    return 0.1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(state,symbol):\n",
    "    if state.count(' ') == 0:\n",
    "        return 3 #draw\n",
    "    elif check_win(state)==True :\n",
    "        return 15 #q-learning agent won\n",
    "    else:\n",
    "        # check if random player won\n",
    "        shadow_state = state.copy()\n",
    "        shadow_state = RandomPlayer('O').make_move(shadow_state)\n",
    "        if check_win(shadow_state)==True:\n",
    "            return -15 #q-learning agent lost\n",
    "    return check_pattern(state,symbol)            \n",
    "\n",
    "def get_qvalue_max(qtable,state,action):\n",
    "    best_act = None\n",
    "    val_max = float('-inf')\n",
    "    \n",
    "    if action is not None and (tuple(state),action) not in qtable:\n",
    "        return action,0\n",
    "    else:\n",
    "        for key, val in qtable.items():\n",
    "            if key[0] == tuple(state) and val > val_max:\n",
    "                val_max = val\n",
    "                best_act = key[1]\n",
    "\n",
    "    return best_act,val_max\n",
    "\n",
    "def print_board(state):\n",
    "    state_as_list = [list(state[i:i+3]) for i in range(0, len(state), 3)]\n",
    "    for row in state_as_list:\n",
    "        print(row)\n",
    "    print(\"-----------------\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QAGENTMODE=\"RANDOM\"\n",
    "\n",
    "class QLearningAgent():\n",
    "    def __init__(self, symbol):\n",
    "        self.symbol = symbol\n",
    "        self.eps=0.4\n",
    "    \n",
    "    def make_move(self, state):\n",
    "        possible_moves=np.where(np.array(state)==' ')[0]\n",
    " \n",
    "        if QAGENTMODE==\"EPSILON_GREEDY\":\n",
    "            # epsilon greedy\n",
    "            if rd.random() < self.eps:\n",
    "                action=np.random.choice(possible_moves)\n",
    "            else:\n",
    "                if all((tuple(state),val) not in qtable for val in possible_moves)==True:\n",
    "                    action=np.random.choice(possible_moves)\n",
    "                else:\n",
    "                    action,_=get_qvalue_max(qtable,state,None)\n",
    "\n",
    "        elif QAGENTMODE==\"RANDOM\":\n",
    "            action=np.random.choice(possible_moves)\n",
    "        else:\n",
    "            print(\"ERROR MODE NOT FOUND\")\n",
    "            return None\n",
    "            \n",
    "        hashable_state=tuple(state)\n",
    "\n",
    "        if (hashable_state,action) not in qtable:\n",
    "            #if new state,action tuple is discovered assign as q-value \n",
    "            # a random number between -1 and 1\n",
    "            qtable[(hashable_state,action)]=np.random.uniform(-1,1)\n",
    "            state[action]=self.symbol #update the state\n",
    "            return state \n",
    "        else:\n",
    "            #if a value already exists for the state, update the q-value\n",
    "            state[action]=self.symbol #update the state \n",
    "            _,qvalue_max=get_qvalue_max(qtable,tuple(state),action)\n",
    "            curr_value=qtable[(hashable_state,action)]\n",
    "            qtable[(hashable_state,action)]=(1-lr)*curr_value+lr*(reward(state,self.symbol)+discount*qvalue_max)\n",
    "        return state\n",
    "\n",
    "    def use_only_qtable(self,state):\n",
    "        action,_=get_qvalue_max(qtable,state,None)\n",
    "        if action is None: #new tuple state,action not found in training\n",
    "            action=np.random.choice(np.where(np.array(state)==' ')[0])\n",
    "        state[action]=self.symbol\n",
    "        return state\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2683c3ef1b3b454dbc2a6ed7afe2f7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[701, 2178, 2121]\n",
      "Q-learning agent win rate: 42.42 %\n",
      "Random player win rate: 43.56 %\n",
      "Draw rate: 14.02 %\n",
      "qtable size: 9040\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "discount=0.5\n",
    "\n",
    "qtable=dict() #key:(state,action) tuple, value: q-value\n",
    "\n",
    "rndply= RandomPlayer('X')\n",
    "qply=QLearningAgent('O')\n",
    "results=[0,0,0] #draws,player1 wins,player2 wins\n",
    "games=5_000\n",
    "\n",
    "for i in tqdm(range(games)):\n",
    "    board=[' ',' ',' ',' ',' ',' ',' ',' ',' ']\n",
    "    player=1 if games<games//2 else 0\n",
    "    while check_win(board)==False and board.count(' ')>0:\n",
    "        if player==1:\n",
    "            # completly random Q-learning agent\n",
    "            board=qply.make_move(board)\n",
    "        else:\n",
    "            board=rndply.make_move(board)\n",
    "        player=1-player\n",
    "    if board.count(' ')==0:\n",
    "        results[0]+=1\n",
    "    else:\n",
    "        results[player+1]+=1\n",
    "print(results)\n",
    "print(\"Q-learning agent win rate:\",results[2]/games*100,\"%\")\n",
    "print(\"Random player win rate:\",results[1]/games*100,\"%\")\n",
    "print(\"Draw rate:\",results[0]/games*100,\"%\")\n",
    "print(\"qtable size:\",len(qtable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play against human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer():\n",
    "    def __init__(self, symbol):\n",
    "        self.symbol = symbol\n",
    "\n",
    "    def make_move(self, state):\n",
    "        while True:\n",
    "            action = int(input(\"Choose your move, avaible moves are: \" + str(np.where(np.array(state) == ' ')[0]) + \"\\n\"))\n",
    "            if state[action] == ' ':\n",
    "                state[action] = self.symbol\n",
    "                return state\n",
    "            else:\n",
    "                print(\"Invalid move!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ']\n",
      "[' ', ' ', ' ']\n",
      "['O', ' ', ' ']\n",
      "-----------------\n",
      "['X', ' ', ' ']\n",
      "[' ', ' ', ' ']\n",
      "['O', ' ', ' ']\n",
      "-----------------\n",
      "['X', ' ', ' ']\n",
      "[' ', ' ', 'O']\n",
      "['O', ' ', ' ']\n",
      "-----------------\n",
      "Invalid move!\n",
      "['X', ' ', ' ']\n",
      "[' ', 'X', 'O']\n",
      "['O', ' ', ' ']\n",
      "-----------------\n",
      "['X', ' ', 'O']\n",
      "[' ', 'X', 'O']\n",
      "['O', ' ', ' ']\n",
      "-----------------\n",
      "Invalid move!\n",
      "['X', ' ', 'O']\n",
      "[' ', 'X', 'O']\n",
      "['O', ' ', 'X']\n",
      "-----------------\n",
      "Human player won!\n"
     ]
    }
   ],
   "source": [
    "qply=QLearningAgent('O')\n",
    "hlpy= HumanPlayer('X')\n",
    "player = 1\n",
    "board=[' ',' ',' ',' ',' ',' ',' ',' ',' ']\n",
    "while check_win(board)==False and board.count(' ')>0:\n",
    "    if player==1:\n",
    "        # Q-learning agent\n",
    "        board=qply.use_only_qtable(board)\n",
    "    else:\n",
    "        board=hlpy.make_move(board)\n",
    "    player=1-player\n",
    "    print_board(board)\n",
    "\n",
    "if board.count(' ')==0:\n",
    "    print(\"Draw!\")\n",
    "if player==1:\n",
    "    print(\"Human player won!\")\n",
    "elif player==0:\n",
    "    print(\"Q-learning won!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
